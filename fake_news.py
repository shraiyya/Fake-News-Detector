# -*- coding: utf-8 -*-
"""fake_news.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ITzSsdjCSaZqp_zRgYp4idQX6Xa6LyP5

###**FAKE NEWS CLASSIFIER USING "TfidfVectorizer"**

Problem Statement : To build a model to accurately classify a piece of news as REAL or FAKE.

Using sklearn,  build a *TfidfVectorizer* on the provided dataset. Then, initialize a *PassiveAggressive Classifier* and fit the model. In the end, the accuracy score and the confusion matrix tell us how well our model fares.
"""

#First we will import all the libraries needed for the project
import numpy as np
import pandas as pd
import itertools    #to return iterators

#sklearn is a machine learning library
import sklearn.metrics as metrics
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer  #import the vectorizer
from sklearn.linear_model import PassiveAggressiveClassifier
from sklearn.metrics import accuracy_score, confusion_matrix  #for finding the accuracy and the confusion matrix
from sklearn.metrics import plot_confusion_matrix             #from the graphical view of the confusion matrix

"""####*Data Exploration*"""

df=pd.read_csv("/content/news.csv")

#tells us the shape = no of rows and columns
print("(rows,columns) = ",end="")
print(df.shape)

#to see first 10 rows of the dataframe
df.head(10)

print(df.columns)  #gives the list of columns

labels=df.label
labels.head(10)

# split the datset for training as well as testing

x_train,x_test,y_train,y_test=train_test_split(df['text'], labels, test_size=0.2, random_state=7)
#20 percent data will be used for training
#the column text will be taken as x_train and the column to be trained is the labels.

"""###*Building and intializing the  TfidfVectorizer*"""

t_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.7) 
#this will stop the english words 
#words which occur more than 70 percent of the artices will be discarded

t_train=t_vectorizer.fit_transform(x_train) 

t_test=t_vectorizer.transform(x_test)

#to find the value of  i from 1 to 100 which gives the highest accuracy we will use a loop
score11=[0]*101
for i in range (1,101):
 pac1=PassiveAggressiveClassifier(i)

 pac1.fit(t_train,y_train)
 y_pred=pac1.predict(t_test)
 score11[i]=accuracy_score(y_test,y_pred)
 print(i,end=" ")
 print(f'Accuracy: {round(score11[i]*100,2)}%')

print("  ")
print("The highest value of accuracy is at max-iter of value " ,end=" ")
print(score11.index(max(score11))) #print the value of iter where value is max

print('ACCURACY IS ',end="")
print(round(max(score11)*100),end=" %")

"""###THE CONFUSION MATRIX"""

m=confusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])
print(m)

"""### *PLOTTING THE CONFUSION MATRIX USING SEABORN*"""

import seaborn as sn
import matplotlib.pyplot as plt

ax=plt.subplot()

sn.heatmap(m ,annot=True,ax = ax,fmt='g',cmap='Blues') 
'''
cmap = blue will set the color 
fmt is used to pass value as string
'''
plt.figure(figsize=(15,15))  #size of figure

ax.set_xlabel('Predicted labels')
ax.set_ylabel('True labels')
ax.xaxis.set_ticklabels(['FAKE', 'REAL'])
ax.yaxis.set_ticklabels(['FAKE', 'REAL'])

ax.set_title('Confusion Matrix of the classifier') #title

